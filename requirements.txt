torch>=2.0.0
transformers==4.47.0
bitsandbytes>=0.39.0
sentencepiece>=0.1.98          # needed by the Phi-3 tokenizer
huggingface_hub>=0.16.4        # only if you plan to run download_model.py on Spaces
gradio>=3.50.0
numpy>=1.24.0
Pillow>=10.0.0
scipy>=1.10.0
llama-cpp-python[server]>=0.2.0